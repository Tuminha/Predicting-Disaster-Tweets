{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8d7e89",
   "metadata": {},
   "source": [
    "# üèãÔ∏è Model Training and Evaluation\n",
    "\n",
    "## üìö Overview\n",
    "\n",
    "This is where the magic happens! You'll implement the **complete training loop** from scratch and learn:\n",
    "- How neural networks actually learn (forward pass, loss, backward pass, optimization)\n",
    "- Training vs. validation\n",
    "- Monitoring training progress\n",
    "- Evaluating model performance\n",
    "- Preventing overfitting\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "1. **Implement a training loop** - the core of deep learning\n",
    "2. **Understand backpropagation** - how gradients update weights\n",
    "3. **Monitor training metrics** - loss, accuracy, validation performance\n",
    "4. **Implement early stopping** - prevent overfitting\n",
    "5. **Evaluate on validation set** - assess generalization\n",
    "6. **Calculate classification metrics** - accuracy, precision, recall, F1\n",
    "7. **Visualize training progress** - loss curves, accuracy plots\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "Before starting, ensure you've completed:\n",
    "- ‚úÖ `00_exploration.ipynb` - Data exploration\n",
    "- ‚úÖ `01_preprocessing.ipynb` - Text preprocessing\n",
    "- ‚úÖ `02_vocab_and_dataloader.ipynb` - Vocabulary and DataLoader\n",
    "- ‚úÖ `03_model_baseline.ipynb` - Model architecture\n",
    "\n",
    "You should have:\n",
    "- Model class defined\n",
    "- DataLoaders ready (train + validation)\n",
    "- Loss function and optimizer configured\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ The Training Loop Explained\n",
    "\n",
    "### The Core Cycle:\n",
    "\n",
    "```\n",
    "For each epoch:\n",
    "    For each batch in training data:\n",
    "        1. Forward Pass: predictions = model(inputs)\n",
    "        2. Calculate Loss: loss = loss_fn(predictions, targets)\n",
    "        3. Backward Pass: loss.backward()  # Compute gradients\n",
    "        4. Optimizer Step: optimizer.step()  # Update weights\n",
    "        5. Zero Gradients: optimizer.zero_grad()  # Reset for next batch\n",
    "        \n",
    "    Validate on validation set\n",
    "    Save best model\n",
    "    Check for early stopping\n",
    "```\n",
    "\n",
    "### Key Concepts:\n",
    "- **Epoch**: One complete pass through the training data\n",
    "- **Batch**: A subset of data (e.g., 32 samples)\n",
    "- **Forward Pass**: Input ‚Üí Model ‚Üí Output\n",
    "- **Loss**: How wrong are the predictions?\n",
    "- **Backward Pass**: Calculate gradients (how to improve)\n",
    "- **Optimizer Step**: Update model parameters using gradients\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Let's Train!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec55d6",
   "metadata": {},
   "source": [
    "## TODO 1: Setup - Import Everything from Previous Notebooks üì¶\n",
    "\n",
    "**Goal**: Load all necessary components from your previous work.\n",
    "\n",
    "**What you need**:\n",
    "1. **Libraries**: torch, pandas, numpy, matplotlib, sklearn metrics\n",
    "2. **Model**: Your DisasterTweetClassifier class\n",
    "3. **Data**: Vocabulary, DataLoaders (train and validation)\n",
    "4. **Config**: Hyperparameters, device, random seed\n",
    "\n",
    "**Creating Train/Val Split**:\n",
    "```python\n",
    "# Load cleaned data\n",
    "df = pd.read_csv('../data/interim/train_cleaned.csv')\n",
    "\n",
    "# Split data (e.g., 80/20 or 90/10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "```\n",
    "\n",
    "**Important**: \n",
    "- Use `stratify=df['target']` to maintain class balance\n",
    "- Create separate DataLoaders for train and validation\n",
    "- Set `shuffle=True` for training, `shuffle=False` for validation\n",
    "\n",
    "**Expected outcome**:\n",
    "- Model, loss_fn, optimizer all initialized\n",
    "- train_loader and val_loader ready\n",
    "- Device set (CPU or GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ac4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Your code here\n",
    "# Setup and imports\n",
    "\n",
    "# Standard libraries\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "\n",
    "\n",
    "# Metrics and visualization\n",
    "\n",
    "\n",
    "# Copy/import your model class from notebook 03\n",
    "\n",
    "\n",
    "# Load vocabulary (from notebook 02)\n",
    "\n",
    "\n",
    "# Create train/val split\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "\n",
    "\n",
    "# Print summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a45267",
   "metadata": {},
   "source": [
    "## TODO 2: Implement Training Function for One Epoch üîÑ\n",
    "\n",
    "**Goal**: Write a function that trains the model for one complete epoch.\n",
    "\n",
    "**Function Structure**:\n",
    "```python\n",
    "def train_one_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()  # Set to training mode\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        # Get data\n",
    "        # Move to device\n",
    "        # Forward pass\n",
    "        # Calculate loss\n",
    "        # Backward pass\n",
    "        # Optimizer step\n",
    "        # Track metrics\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "```\n",
    "\n",
    "**Key Steps in Loop**:\n",
    "1. `model.train()` - Enable dropout, batch norm training mode\n",
    "2. Get texts and labels from batch\n",
    "3. Move tensors to device\n",
    "4. Zero gradients: `optimizer.zero_grad()`\n",
    "5. Forward pass: `outputs = model(texts)`\n",
    "6. Calculate loss: `loss = loss_fn(outputs, labels)`\n",
    "7. Backward pass: `loss.backward()`\n",
    "8. Update weights: `optimizer.step()`\n",
    "9. Track loss and accuracy\n",
    "\n",
    "**Accuracy Calculation**:\n",
    "```python\n",
    "# Convert logits to predictions (0 or 1)\n",
    "predictions = (torch.sigmoid(outputs) > 0.5).float()\n",
    "correct += (predictions == labels).sum().item()\n",
    "```\n",
    "\n",
    "**Hints**:\n",
    "- Accumulate loss: `total_loss += loss.item()`\n",
    "- Track number of samples: `total += labels.size(0)`\n",
    "- Return average loss: `total_loss / len(dataloader)`\n",
    "- Return accuracy: `correct / total`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5db00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Your code here\n",
    "def train_one_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    \"\"\"Train model for one epoch.\"\"\"\n",
    "    # TODO: Set model to training mode\n",
    "    pass\n",
    "    \n",
    "    # TODO: Initialize tracking variables\n",
    "    \n",
    "    # TODO: Loop through batches\n",
    "    # for texts, labels in dataloader:\n",
    "        # TODO: Move to device\n",
    "        # TODO: Zero gradients\n",
    "        # TODO: Forward pass\n",
    "        # TODO: Calculate loss\n",
    "        # TODO: Backward pass\n",
    "        # TODO: Optimizer step\n",
    "        # TODO: Track metrics\n",
    "        \n",
    "    # TODO: Calculate and return average metrics\n",
    "    # return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10249c77",
   "metadata": {},
   "source": [
    "## TODO 3: Implement Validation Function üìä\n",
    "\n",
    "**Goal**: Evaluate model on validation set (no gradient updates).\n",
    "\n",
    "**Key Difference from Training**:\n",
    "- `model.eval()` - Disable dropout, use batch norm in eval mode\n",
    "- `torch.no_grad()` - Don't track gradients (saves memory, faster)\n",
    "- No `backward()` or `optimizer.step()`\n",
    "\n",
    "**Function Structure**:\n",
    "```python\n",
    "def validate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Don't track gradients\n",
    "        for texts, labels in dataloader:\n",
    "            # Move to device\n",
    "            # Forward pass only\n",
    "            # Calculate loss and accuracy\n",
    "            \n",
    "    return avg_loss, accuracy\n",
    "```\n",
    "\n",
    "**Why validation?**:\n",
    "- Check if model generalizes to unseen data\n",
    "- Detect overfitting (train acc high, val acc low)\n",
    "- Decide when to stop training\n",
    "\n",
    "---\n",
    "\n",
    "## TODO 4: Implement Complete Training Loop üîÅ\n",
    "\n",
    "**Goal**: Train for multiple epochs with validation and progress tracking.\n",
    "\n",
    "**Structure**:\n",
    "```python\n",
    "def train_model(model, train_loader, val_loader, loss_fn, optimizer, \n",
    "                num_epochs, device):\n",
    "    history = {'train_loss': [], 'train_acc': [], \n",
    "               'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train for one epoch\n",
    "        train_loss, train_acc = train_one_epoch(...)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(...)\n",
    "        \n",
    "        # Store metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        # ... store others\n",
    "        \n",
    "        # Print progress\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Optional: Save best model, early stopping\n",
    "        \n",
    "    return history\n",
    "```\n",
    "\n",
    "**Number of Epochs**: Start with 10-20, adjust based on convergence\n",
    "\n",
    "---\n",
    "\n",
    "## TODO 5: Train Your Model üöÄ\n",
    "\n",
    "Execute the training! Monitor for:\n",
    "- **Loss decreasing** - Model is learning\n",
    "- **Accuracy increasing** - Predictions improving  \n",
    "- **Val metrics similar to train** - Good generalization\n",
    "- **Val metrics much worse than train** - Overfitting! Stop or regularize\n",
    "\n",
    "---\n",
    "\n",
    "## TODO 6: Evaluate and Calculate Metrics üìà\n",
    "\n",
    "Calculate detailed classification metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: Of predicted disasters, how many are real?\n",
    "- **Recall**: Of real disasters, how many did we catch?\n",
    "- **F1-Score**: Harmonic mean of precision and recall (competition metric!)\n",
    "- **Confusion Matrix**: Visualize true/false positives/negatives\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Get predictions on validation set\n",
    "# Calculate metrics\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## TODO 7: Visualize Training Progress üìä\n",
    "\n",
    "Create plots to understand training:\n",
    "1. **Loss curves**: Train vs. Val loss over epochs\n",
    "2. **Accuracy curves**: Train vs. Val accuracy over epochs\n",
    "3. **Confusion matrix**: Heatmap of predictions\n",
    "\n",
    "---\n",
    "\n",
    "## TODO 8: Save Your Trained Model üíæ\n",
    "\n",
    "Save the model for inference and submission:\n",
    "```python\n",
    "torch.save(model.state_dict(), '../models/disaster_classifier.pth')\n",
    "torch.save(history, '../models/training_history.pkl')\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
