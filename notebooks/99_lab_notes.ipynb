{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cdf805",
   "metadata": {},
   "source": [
    "# 🧪 Lab Notes & Experiments\n",
    "\n",
    "**Project**: Natural Language Processing with Disaster Tweets  \n",
    "**Competition**: Kaggle NLP Getting Started  \n",
    "**Timeline**: October 2025  \n",
    "**Goal**: Learn PyTorch fundamentals through hands-on implementation\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Experiment Log\n",
    "\n",
    "### Experiment 1: Baseline Model - First Attempt\n",
    "**Date**: October 2025  \n",
    "**Goal**: Establish baseline performance with simple architecture\n",
    "\n",
    "**Architecture**:\n",
    "- Vocabulary: 3,160 words (min_freq=5 likely)\n",
    "- Embedding dim: 100\n",
    "- Hidden dim: 128\n",
    "- Dropout: 0.5\n",
    "- Learning rate: 0.001\n",
    "- Optimizer: Adam\n",
    "- Epochs: 10\n",
    "\n",
    "**Results**:\n",
    "- **Validation Accuracy**: 72.0%\n",
    "- **Validation F1**: 0.68\n",
    "- **Train Accuracy**: 98.4%\n",
    "- **Train/Val Gap**: 26.4% ❌\n",
    "\n",
    "**Observations**:\n",
    "- 🚨 **SEVERE OVERFITTING**: Model memorizing training data\n",
    "- Train loss → 0, Val loss → 18 (complete divergence)\n",
    "- Training accuracy near perfect, validation stuck at 72%\n",
    "- Model has too much capacity for the data\n",
    "\n",
    "**Conclusion**:\n",
    "- ❌ **DISCARD**: Architecture needs major changes\n",
    "- **Root Cause**: 329K parameters for only 6K training samples (54 params/sample!)\n",
    "- **Lesson**: Model capacity must match dataset size\n",
    "\n",
    "**Key Insight**: High training accuracy is NOT a success metric if validation lags behind!\n",
    "\n",
    "---\n",
    "\n",
    "### Experiment 2: Vocabulary Expansion + Architecture Reduction\n",
    "**Date**: October 2025  \n",
    "**Goal**: Fix overfitting through vocabulary expansion and smaller network\n",
    "\n",
    "**Changes**:\n",
    "- ✅ Vocabulary: 3,160 → **41,400 words** (min_freq=1)\n",
    "  - Rationale: Capture rare disaster-specific terms\n",
    "- ✅ Embedding dim: 100 → **50** (50% reduction)\n",
    "  - Rationale: Less capacity to memorize\n",
    "- ✅ Hidden dim: 128 → **64** (50% reduction)\n",
    "  - Rationale: Simpler model for better generalization\n",
    "\n",
    "**Results**:\n",
    "- **Validation Accuracy**: 77.7% (+5.7% 🎉)\n",
    "- **Validation F1**: 0.74 (+0.06)\n",
    "- **Train Accuracy**: 92.8%\n",
    "- **Train/Val Gap**: 15.1% (improved from 26.4%)\n",
    "\n",
    "**Observations**:\n",
    "- ✅ Loss curves much healthier (both decreasing together)\n",
    "- ✅ Validation loss plateaus around 0.50 (vs 18 before!)\n",
    "- ✅ Both accuracy curves rise together initially\n",
    "- ⚠️ Still some overfitting but manageable\n",
    "\n",
    "**Conclusion**:\n",
    "- ✅ **MAJOR SUCCESS**: Right direction!\n",
    "- Vocabulary size MATTERS for NLP\n",
    "- Smaller networks can generalize better\n",
    "- Proved: Less is more!\n",
    "\n",
    "**Key Insight**: Large vocabulary + small network > small vocabulary + large network\n",
    "\n",
    "---\n",
    "\n",
    "### Experiment 3: Aggressive Regularization\n",
    "**Date**: October 2025  \n",
    "**Goal**: Further reduce overfitting with regularization techniques\n",
    "\n",
    "**Changes**:\n",
    "- ✅ Learning rate: 0.001 → **0.00001** (100× slower!)\n",
    "  - Rationale: Careful, gradual learning\n",
    "- ✅ Weight decay: None → **1e-4**\n",
    "  - Rationale: L2 regularization penalizes large weights\n",
    "- ✅ Dropout: 0.5 → **0.6** (likely)\n",
    "  - Rationale: More aggressive dropout\n",
    "- ✅ Early stopping: 10 → **4 epochs**\n",
    "  - Rationale: Stop before overfitting sets in\n",
    "\n",
    "**Results**:\n",
    "- **Validation Accuracy**: 79.4% (+1.7%)\n",
    "- **Validation F1**: 0.75 (+0.01)\n",
    "- **Train Accuracy**: 85.7%\n",
    "- **Train/Val Gap**: 5.9% ✅ (near-perfect!)\n",
    "\n",
    "**Observations**:\n",
    "- 🎯 **EXCELLENT generalization**: Only 6% gap!\n",
    "- Train and val losses stay close throughout training\n",
    "- Best val performance at Epoch 4\n",
    "- Both curves still improving (could train slightly longer)\n",
    "\n",
    "**Conclusion**:\n",
    "- ✅ **KEEP**: This is the sweet spot!\n",
    "- Learning rate had HUGE impact (biggest single change)\n",
    "- Multiple regularization techniques stack effectively\n",
    "- Model learning generalizable patterns, not memorizing\n",
    "\n",
    "**Key Insight**: Learning rate is often the most important hyperparameter!\n",
    "\n",
    "---\n",
    "\n",
    "### Experiment 4: Extended Training\n",
    "**Date**: October 2025  \n",
    "**Goal**: Push for 80% validation accuracy milestone\n",
    "\n",
    "**Changes**:\n",
    "- ✅ Epochs: 4 → **6**\n",
    "  - Rationale: Both curves still improving at Epoch 4\n",
    "\n",
    "**Results**:\n",
    "- **Validation Accuracy**: 80.0% (+0.6% 🎯)\n",
    "- **Validation F1**: 0.76 (+0.01)\n",
    "- **Train Accuracy**: 93.0%\n",
    "- **Train/Val Gap**: 13.0% (increased from 5.9%)\n",
    "- **Peak Validation**: Epoch 5 (79.8%)\n",
    "\n",
    "**Observations**:\n",
    "- 🎯 **HIT THE TARGET**: 80% validation accuracy!\n",
    "- Val loss started rising after Epoch 3\n",
    "- Best performance was actually Epoch 5 (79.8%)\n",
    "- Training for 6 epochs increased overfitting slightly\n",
    "\n",
    "**Conclusion**:\n",
    "- ✅ **SUCCESS**: Achieved 80% goal!\n",
    "- ⚠️ Should have stopped at Epoch 5\n",
    "- Mild overfitting returned (13% gap)\n",
    "- Demonstrates importance of early stopping\n",
    "\n",
    "**Key Insight**: More training ≠ better performance. Monitor validation loss!\n",
    "\n",
    "---\n",
    "\n",
    "### Experiment 5: Kaggle Submission\n",
    "**Date**: October 2025  \n",
    "**Goal**: Test generalization on unseen test set\n",
    "\n",
    "**Model Used**: Experiment 4 (6 epochs, best checkpoint)\n",
    "\n",
    "**Results**:\n",
    "- **Public F1-Score**: 0.78516\n",
    "- **Validation F1**: 0.76\n",
    "- **Difference**: +0.026 (+2.6%)\n",
    "- **Leaderboard Rank**: #658\n",
    "\n",
    "**Observations**:\n",
    "- 🎉 **TEST > VALIDATION**: Rare and good sign!\n",
    "- Model generalized better to test than validation\n",
    "- No overfitting to training set\n",
    "- Preprocessing pipeline works on new data\n",
    "\n",
    "**Conclusion**:\n",
    "- ✅ **EXCELLENT**: Better generalization than expected!\n",
    "- Proves robust preprocessing\n",
    "- Confirms hyperparameter choices were good\n",
    "- Solid baseline for from-scratch implementation\n",
    "\n",
    "**Key Insight**: When test > validation, you did something right!\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Complete Experiment Comparison\n",
    "\n",
    "| Exp | Vocab | Emb | Hidden | LR | Dropout | WD | Epochs | Val Acc | Val F1 | Train/Val Gap | Status |\n",
    "|-----|-------|-----|--------|----|---------|----|--------|---------|--------|---------------|--------|\n",
    "| **1** | 3.2K | 100 | 128 | 1e-3 | 0.5 | 0 | 10 | 72.0% | 0.68 | **26.4%** ❌ | Overfit |\n",
    "| **2** | 41K | 50 | 64 | 1e-3 | 0.6? | 0 | 10 | 77.7% | 0.74 | 15.1% | Better |\n",
    "| **3** | 41K | 50 | 64 | **1e-5** | 0.6 | **1e-4** | **4** | 79.4% | 0.75 | **5.9%** ✅ | Excellent |\n",
    "| **4** | 41K | 50 | 64 | 1e-5 | 0.6 | 1e-4 | **6** | **80.0%** | **0.76** | 13.0% | Goal! |\n",
    "| **5** | 41K | 50 | 64 | 1e-5 | 0.6 | 1e-4 | 6 | **Test: 78.5%** | **0.785** | N/A | Submitted |\n",
    "\n",
    "**Progression**: 72% → 77.7% → 79.4% → 80.0% → **78.5% (test)**\n",
    "\n",
    "**Total Improvement**: +8.5% validation, +10.5% from first model to test!\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Ideas Tried & Lessons Learned\n",
    "\n",
    "### ✅ What Worked:\n",
    "\n",
    "1. **Large Vocabulary (41K words)**\n",
    "   - Captured rare disaster terms (tsunami, wildfire, evacuation)\n",
    "   - min_freq=1 was crucial\n",
    "   - More words > fewer words for NLP\n",
    "\n",
    "2. **Smaller Network Architecture**\n",
    "   - Embedding: 100 → 50\n",
    "   - Hidden: 128 → 64\n",
    "   - Less capacity = better generalization\n",
    "   - Counter-intuitive but effective!\n",
    "\n",
    "3. **Very Low Learning Rate (1e-5)**\n",
    "   - Biggest single improvement\n",
    "   - Slow, careful learning\n",
    "   - Prevented overfitting dramatically\n",
    "   - Worth the longer training time\n",
    "\n",
    "4. **Multiple Regularization Stacking**\n",
    "   - Dropout (0.6) + Weight Decay (1e-4) + Early Stopping\n",
    "   - Each contributed ~1-2%\n",
    "   - Combined effect was powerful\n",
    "\n",
    "5. **Early Stopping (4-6 epochs)**\n",
    "   - Validation loss was the guide\n",
    "   - Best performance at Epoch 5\n",
    "   - Prevented overtraining\n",
    "\n",
    "### ❌ What Didn't Work:\n",
    "\n",
    "1. **Large Network with Small Vocab**\n",
    "   - 329K params for 6K samples = disaster\n",
    "   - Model memorized everything\n",
    "   - High training accuracy is a trap!\n",
    "\n",
    "2. **High Learning Rate (0.001)**\n",
    "   - Too aggressive for this dataset\n",
    "   - Caused overfitting\n",
    "   - Validation loss diverged\n",
    "\n",
    "3. **Training Too Long (10 epochs)**\n",
    "   - Validation peaked at Epoch 5\n",
    "   - Extra epochs hurt performance\n",
    "   - Wasted compute and increased overfitting\n",
    "\n",
    "### 🤔 Surprises:\n",
    "\n",
    "1. **Test Score > Validation Score**\n",
    "   - Usually it's the opposite!\n",
    "   - Shows excellent generalization\n",
    "   - Robust preprocessing pipeline\n",
    "\n",
    "2. **Vocabulary Size > Model Size**\n",
    "   - Expected larger embeddings to help\n",
    "   - Actually, large vocab + small embeddings won\n",
    "   - Representation diversity > capacity\n",
    "\n",
    "3. **100× Learning Rate Reduction**\n",
    "   - Didn't expect such a huge change to work\n",
    "   - 1e-5 is very slow but highly effective\n",
    "   - Sometimes patience is the answer\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Ideas to Try Next\n",
    "\n",
    "### Phase 2: Transformers (High Priority)\n",
    "\n",
    "- [x] Complete Phase 1 baseline\n",
    "- [ ] **Implement DistilBERT** (smallest, fastest)\n",
    "  - Expected: +5-7% F1\n",
    "  - Target: 0.82-0.83 F1\n",
    "- [ ] **Try RoBERTa** (more powerful)\n",
    "  - Expected: +6-8% F1\n",
    "  - Target: 0.83-0.84 F1\n",
    "- [ ] **Fine-tune carefully**\n",
    "  - Lower LR (1e-5 or 2e-5)\n",
    "  - Few epochs (2-4)\n",
    "  - Monitor for overfitting\n",
    "\n",
    "### Quick Wins (Medium Priority)\n",
    "\n",
    "- [ ] **Optimize Decision Threshold**\n",
    "  - Currently using 0.5\n",
    "  - F1-score maximized at different threshold\n",
    "  - Expected: +1-2% F1\n",
    "\n",
    "- [ ] **Try Max Pooling**\n",
    "  - Currently using mean pooling\n",
    "  - Max might capture stronger signals\n",
    "  - Expected: +0.5-1% F1\n",
    "\n",
    "- [ ] **Ensemble Multiple Models**\n",
    "  - Combine 3-5 different models\n",
    "  - Majority vote or average probabilities\n",
    "  - Expected: +2-3% F1\n",
    "\n",
    "### Advanced (Low Priority for Now)\n",
    "\n",
    "- [ ] LSTM/GRU architecture\n",
    "- [ ] Pre-trained embeddings (GloVe)\n",
    "- [ ] Data augmentation\n",
    "- [ ] Cross-validation\n",
    "- [ ] Pseudo-labeling\n",
    "\n",
    "---\n",
    "\n",
    "## 🐛 Debugging Notes\n",
    "\n",
    "### Issue 1: AttributeError - float.split()\n",
    "**Problem**: Vocabulary building failed on NaN values  \n",
    "**Cause**: `text_clean` column had NaN (float) instead of strings  \n",
    "**Solution**: \n",
    "- Added `fillna(\"UNK\")` in preprocessing\n",
    "- Added type checking before `.split()`\n",
    "- Ensured preprocessing returns strings, not NaN\n",
    "\n",
    "**Lesson**: Always validate data types after preprocessing!\n",
    "\n",
    "### Issue 2: KeyError in DataLoader\n",
    "**Problem**: `KeyError: 1335` when iterating through batches  \n",
    "**Cause**: Using label-based indexing `[idx]` instead of positional `.iloc[idx]`  \n",
    "**Solution**: Changed to `.iloc[idx]` in `__getitem__`  \n",
    "\n",
    "**Lesson**: Pandas Series indexing can be tricky!\n",
    "\n",
    "### Issue 3: Import Error - ModuleNotFoundError: 'src'\n",
    "**Problem**: Can't import from `src.models.baseline_model`  \n",
    "**Cause**: Python path doesn't include project root  \n",
    "**Solution**: \n",
    "```python\n",
    "import sys, os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "```\n",
    "\n",
    "**Lesson**: Always fix Python path BEFORE importing custom modules!\n",
    "\n",
    "### Issue 4: RuntimeError - mat1 and mat2 shapes mismatch\n",
    "**Problem**: Matrix multiplication error in forward pass  \n",
    "**Cause**: Missing pooling step after embedding  \n",
    "**Solution**: Added `pooled = x.mean(dim=1)` to aggregate sequence  \n",
    "\n",
    "**Lesson**: Always track tensor shapes through the network!\n",
    "\n",
    "---\n",
    "\n",
    "## 💭 Key Learnings & Insights\n",
    "\n",
    "### On Overfitting:\n",
    "> \"High training accuracy is not success—it's often a warning sign. The train/val gap is your most important metric.\"\n",
    "\n",
    "### On Hyperparameters:\n",
    "> \"Learning rate matters more than any other hyperparameter. Spend time here first.\"\n",
    "\n",
    "### On Architecture:\n",
    "> \"Bigger is not always better. Sometimes a smaller model learns more general patterns.\"\n",
    "\n",
    "### On Data:\n",
    "> \"In NLP, vocabulary richness often beats model complexity. Don't throw away rare words too quickly.\"\n",
    "\n",
    "### On Patience:\n",
    "> \"Training slower (low LR) with fewer epochs often beats training faster for longer.\"\n",
    "\n",
    "### On Validation:\n",
    "> \"Early stopping based on validation loss is not optional—it's essential.\"\n",
    "\n",
    "### On Generalization:\n",
    "> \"When test performance > validation performance, you've achieved something special. It means your model truly learned, not memorized.\"\n",
    "\n",
    "---\n",
    "\n",
    "## 🎓 Skills Developed\n",
    "\n",
    "Through this project, I learned:\n",
    "\n",
    "1. ✅ **End-to-end ML pipeline** - From raw data to Kaggle submission\n",
    "2. ✅ **Systematic debugging** - Identify and fix issues methodically\n",
    "3. ✅ **Hyperparameter tuning** - Test hypotheses and iterate\n",
    "4. ✅ **Overfitting diagnosis** - Recognize and fix through multiple techniques\n",
    "5. ✅ **PyTorch fundamentals** - Build custom models, datasets, training loops\n",
    "6. ✅ **NLP preprocessing** - Text cleaning, tokenization, vocabulary building\n",
    "7. ✅ **Evaluation metrics** - Precision, recall, F1, confusion matrices\n",
    "8. ✅ **Training dynamics** - Interpret loss curves, accuracy plots\n",
    "9. ✅ **Professional workflow** - Version control, documentation, reproducibility\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Next Milestones\n",
    "\n",
    "- [x] **Phase 1**: PyTorch Fundamentals (72% → 80% → 78.5% test) ✅\n",
    "- [ ] **Phase 2**: Transformers (Target: 82-83% test)\n",
    "- [ ] **Phase 3**: Ensemble & Optimization (Target: 84%+ test, Top 10%)\n",
    "\n",
    "**Current Status**: Ready for Phase 2! 🚀\n",
    "\n",
    "---\n",
    "\n",
    "## 🙏 Acknowledgments\n",
    "\n",
    "**Learning Resources:**\n",
    "- Kaggle Competition: Natural Language Processing with Disaster Tweets\n",
    "- PyTorch Documentation\n",
    "- Codecademy ML Course\n",
    "- Trial, error, and persistence!\n",
    "\n",
    "**Key Insight:**\n",
    "> \"It ain't much, but it's honest work.\" 🚜\n",
    "> \n",
    "> Building from scratch teaches 10× more than using pre-built solutions.\n",
    "\n",
    "---\n",
    "\n",
    "**Last Updated**: October 2025  \n",
    "**Status**: Phase 1 Complete ✅ | Kaggle Score: 0.78516 | Rank: #658\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
